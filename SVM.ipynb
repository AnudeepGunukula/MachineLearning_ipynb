{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"SVM.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1BT0pn1XhD56aF8ynZ31a6-86hdxufx4_","authorship_tag":"ABX9TyOUuX6fyCA4BlKeiffArdxo"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"3rA_7fT49RHB","colab_type":"code","colab":{}},"source":["from sklearn.datasets import load_iris\n","import pandas as pd"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pxJ_c5XTpWQg","colab_type":"code","colab":{}},"source":["iris=load_iris()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WieQUJOypb91","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1597407421202,"user_tz":-330,"elapsed":1316,"user":{"displayName":"john wickson","photoUrl":"","userId":"02886435677777830514"}},"outputId":"924a706e-0d26-4ab9-fbed-7962e7d75907"},"source":["dir(iris)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['DESCR', 'data', 'feature_names', 'filename', 'target', 'target_names']"]},"metadata":{"tags":[]},"execution_count":398}]},{"cell_type":"code","metadata":{"id":"KPYJsEh5pepu","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":402},"executionInfo":{"status":"ok","timestamp":1597407421204,"user_tz":-330,"elapsed":1299,"user":{"displayName":"john wickson","photoUrl":"","userId":"02886435677777830514"}},"outputId":"0b0e5e20-6317-4372-ce71-a0090d8f0520"},"source":["df=pd.DataFrame(iris.data,columns=iris.feature_names)\n","df"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sepal length (cm)</th>\n","      <th>sepal width (cm)</th>\n","      <th>petal length (cm)</th>\n","      <th>petal width (cm)</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>5.1</td>\n","      <td>3.5</td>\n","      <td>1.4</td>\n","      <td>0.2</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>4.9</td>\n","      <td>3.0</td>\n","      <td>1.4</td>\n","      <td>0.2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>4.7</td>\n","      <td>3.2</td>\n","      <td>1.3</td>\n","      <td>0.2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4.6</td>\n","      <td>3.1</td>\n","      <td>1.5</td>\n","      <td>0.2</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5.0</td>\n","      <td>3.6</td>\n","      <td>1.4</td>\n","      <td>0.2</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>145</th>\n","      <td>6.7</td>\n","      <td>3.0</td>\n","      <td>5.2</td>\n","      <td>2.3</td>\n","    </tr>\n","    <tr>\n","      <th>146</th>\n","      <td>6.3</td>\n","      <td>2.5</td>\n","      <td>5.0</td>\n","      <td>1.9</td>\n","    </tr>\n","    <tr>\n","      <th>147</th>\n","      <td>6.5</td>\n","      <td>3.0</td>\n","      <td>5.2</td>\n","      <td>2.0</td>\n","    </tr>\n","    <tr>\n","      <th>148</th>\n","      <td>6.2</td>\n","      <td>3.4</td>\n","      <td>5.4</td>\n","      <td>2.3</td>\n","    </tr>\n","    <tr>\n","      <th>149</th>\n","      <td>5.9</td>\n","      <td>3.0</td>\n","      <td>5.1</td>\n","      <td>1.8</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>150 rows × 4 columns</p>\n","</div>"],"text/plain":["     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n","0                  5.1               3.5                1.4               0.2\n","1                  4.9               3.0                1.4               0.2\n","2                  4.7               3.2                1.3               0.2\n","3                  4.6               3.1                1.5               0.2\n","4                  5.0               3.6                1.4               0.2\n","..                 ...               ...                ...               ...\n","145                6.7               3.0                5.2               2.3\n","146                6.3               2.5                5.0               1.9\n","147                6.5               3.0                5.2               2.0\n","148                6.2               3.4                5.4               2.3\n","149                5.9               3.0                5.1               1.8\n","\n","[150 rows x 4 columns]"]},"metadata":{"tags":[]},"execution_count":399}]},{"cell_type":"code","metadata":{"id":"ntvSS6NRrMar","colab_type":"code","colab":{}},"source":["hdf=pd.DataFrame(iris.target,columns=['target'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3CpEnPK_unN7","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":402},"executionInfo":{"status":"ok","timestamp":1597407421207,"user_tz":-330,"elapsed":1261,"user":{"displayName":"john wickson","photoUrl":"","userId":"02886435677777830514"}},"outputId":"9d47d2c9-9f31-41ae-d4e5-9da27711fe6e"},"source":["df=df.join(hdf)\n","df"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sepal length (cm)</th>\n","      <th>sepal width (cm)</th>\n","      <th>petal length (cm)</th>\n","      <th>petal width (cm)</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>5.1</td>\n","      <td>3.5</td>\n","      <td>1.4</td>\n","      <td>0.2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>4.9</td>\n","      <td>3.0</td>\n","      <td>1.4</td>\n","      <td>0.2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>4.7</td>\n","      <td>3.2</td>\n","      <td>1.3</td>\n","      <td>0.2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4.6</td>\n","      <td>3.1</td>\n","      <td>1.5</td>\n","      <td>0.2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5.0</td>\n","      <td>3.6</td>\n","      <td>1.4</td>\n","      <td>0.2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>145</th>\n","      <td>6.7</td>\n","      <td>3.0</td>\n","      <td>5.2</td>\n","      <td>2.3</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>146</th>\n","      <td>6.3</td>\n","      <td>2.5</td>\n","      <td>5.0</td>\n","      <td>1.9</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>147</th>\n","      <td>6.5</td>\n","      <td>3.0</td>\n","      <td>5.2</td>\n","      <td>2.0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>148</th>\n","      <td>6.2</td>\n","      <td>3.4</td>\n","      <td>5.4</td>\n","      <td>2.3</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>149</th>\n","      <td>5.9</td>\n","      <td>3.0</td>\n","      <td>5.1</td>\n","      <td>1.8</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>150 rows × 5 columns</p>\n","</div>"],"text/plain":["     sepal length (cm)  sepal width (cm)  ...  petal width (cm)  target\n","0                  5.1               3.5  ...               0.2       0\n","1                  4.9               3.0  ...               0.2       0\n","2                  4.7               3.2  ...               0.2       0\n","3                  4.6               3.1  ...               0.2       0\n","4                  5.0               3.6  ...               0.2       0\n","..                 ...               ...  ...               ...     ...\n","145                6.7               3.0  ...               2.3       2\n","146                6.3               2.5  ...               1.9       2\n","147                6.5               3.0  ...               2.0       2\n","148                6.2               3.4  ...               2.3       2\n","149                5.9               3.0  ...               1.8       2\n","\n","[150 rows x 5 columns]"]},"metadata":{"tags":[]},"execution_count":401}]},{"cell_type":"code","metadata":{"id":"8svMq0ggrgkW","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1597407421208,"user_tz":-330,"elapsed":1240,"user":{"displayName":"john wickson","photoUrl":"","userId":"02886435677777830514"}},"outputId":"64ee03f0-dcfe-492a-be3d-38e005072972"},"source":["iris.target_names"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['setosa', 'versicolor', 'virginica'], dtype='<U10')"]},"metadata":{"tags":[]},"execution_count":402}]},{"cell_type":"code","metadata":{"id":"d0s70zcqurno","colab_type":"code","colab":{}},"source":["df0=df[df.target==0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pjJwk-FKrs--","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1597407421211,"user_tz":-330,"elapsed":1206,"user":{"displayName":"john wickson","photoUrl":"","userId":"02886435677777830514"}},"outputId":"da4ecd51-dc38-476d-8060-7166eb2f8571"},"source":["df0"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sepal length (cm)</th>\n","      <th>sepal width (cm)</th>\n","      <th>petal length (cm)</th>\n","      <th>petal width (cm)</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>5.1</td>\n","      <td>3.5</td>\n","      <td>1.4</td>\n","      <td>0.2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>4.9</td>\n","      <td>3.0</td>\n","      <td>1.4</td>\n","      <td>0.2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>4.7</td>\n","      <td>3.2</td>\n","      <td>1.3</td>\n","      <td>0.2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4.6</td>\n","      <td>3.1</td>\n","      <td>1.5</td>\n","      <td>0.2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5.0</td>\n","      <td>3.6</td>\n","      <td>1.4</td>\n","      <td>0.2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>5.4</td>\n","      <td>3.9</td>\n","      <td>1.7</td>\n","      <td>0.4</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>4.6</td>\n","      <td>3.4</td>\n","      <td>1.4</td>\n","      <td>0.3</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>5.0</td>\n","      <td>3.4</td>\n","      <td>1.5</td>\n","      <td>0.2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>4.4</td>\n","      <td>2.9</td>\n","      <td>1.4</td>\n","      <td>0.2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>4.9</td>\n","      <td>3.1</td>\n","      <td>1.5</td>\n","      <td>0.1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>5.4</td>\n","      <td>3.7</td>\n","      <td>1.5</td>\n","      <td>0.2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>4.8</td>\n","      <td>3.4</td>\n","      <td>1.6</td>\n","      <td>0.2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>4.8</td>\n","      <td>3.0</td>\n","      <td>1.4</td>\n","      <td>0.1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>4.3</td>\n","      <td>3.0</td>\n","      <td>1.1</td>\n","      <td>0.1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>5.8</td>\n","      <td>4.0</td>\n","      <td>1.2</td>\n","      <td>0.2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>5.7</td>\n","      <td>4.4</td>\n","      <td>1.5</td>\n","      <td>0.4</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>5.4</td>\n","      <td>3.9</td>\n","      <td>1.3</td>\n","      <td>0.4</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>5.1</td>\n","      <td>3.5</td>\n","      <td>1.4</td>\n","      <td>0.3</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>5.7</td>\n","      <td>3.8</td>\n","      <td>1.7</td>\n","      <td>0.3</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>5.1</td>\n","      <td>3.8</td>\n","      <td>1.5</td>\n","      <td>0.3</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>5.4</td>\n","      <td>3.4</td>\n","      <td>1.7</td>\n","      <td>0.2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>5.1</td>\n","      <td>3.7</td>\n","      <td>1.5</td>\n","      <td>0.4</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>4.6</td>\n","      <td>3.6</td>\n","      <td>1.0</td>\n","      <td>0.2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>5.1</td>\n","      <td>3.3</td>\n","      <td>1.7</td>\n","      <td>0.5</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>4.8</td>\n","      <td>3.4</td>\n","      <td>1.9</td>\n","      <td>0.2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>5.0</td>\n","      <td>3.0</td>\n","      <td>1.6</td>\n","      <td>0.2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>5.0</td>\n","      <td>3.4</td>\n","      <td>1.6</td>\n","      <td>0.4</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>5.2</td>\n","      <td>3.5</td>\n","      <td>1.5</td>\n","      <td>0.2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>28</th>\n","      <td>5.2</td>\n","      <td>3.4</td>\n","      <td>1.4</td>\n","      <td>0.2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>4.7</td>\n","      <td>3.2</td>\n","      <td>1.6</td>\n","      <td>0.2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>30</th>\n","      <td>4.8</td>\n","      <td>3.1</td>\n","      <td>1.6</td>\n","      <td>0.2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>31</th>\n","      <td>5.4</td>\n","      <td>3.4</td>\n","      <td>1.5</td>\n","      <td>0.4</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>32</th>\n","      <td>5.2</td>\n","      <td>4.1</td>\n","      <td>1.5</td>\n","      <td>0.1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>33</th>\n","      <td>5.5</td>\n","      <td>4.2</td>\n","      <td>1.4</td>\n","      <td>0.2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>34</th>\n","      <td>4.9</td>\n","      <td>3.1</td>\n","      <td>1.5</td>\n","      <td>0.2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>35</th>\n","      <td>5.0</td>\n","      <td>3.2</td>\n","      <td>1.2</td>\n","      <td>0.2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>36</th>\n","      <td>5.5</td>\n","      <td>3.5</td>\n","      <td>1.3</td>\n","      <td>0.2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>37</th>\n","      <td>4.9</td>\n","      <td>3.6</td>\n","      <td>1.4</td>\n","      <td>0.1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>38</th>\n","      <td>4.4</td>\n","      <td>3.0</td>\n","      <td>1.3</td>\n","      <td>0.2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>39</th>\n","      <td>5.1</td>\n","      <td>3.4</td>\n","      <td>1.5</td>\n","      <td>0.2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>40</th>\n","      <td>5.0</td>\n","      <td>3.5</td>\n","      <td>1.3</td>\n","      <td>0.3</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>41</th>\n","      <td>4.5</td>\n","      <td>2.3</td>\n","      <td>1.3</td>\n","      <td>0.3</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>42</th>\n","      <td>4.4</td>\n","      <td>3.2</td>\n","      <td>1.3</td>\n","      <td>0.2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>43</th>\n","      <td>5.0</td>\n","      <td>3.5</td>\n","      <td>1.6</td>\n","      <td>0.6</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>44</th>\n","      <td>5.1</td>\n","      <td>3.8</td>\n","      <td>1.9</td>\n","      <td>0.4</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>45</th>\n","      <td>4.8</td>\n","      <td>3.0</td>\n","      <td>1.4</td>\n","      <td>0.3</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>46</th>\n","      <td>5.1</td>\n","      <td>3.8</td>\n","      <td>1.6</td>\n","      <td>0.2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>47</th>\n","      <td>4.6</td>\n","      <td>3.2</td>\n","      <td>1.4</td>\n","      <td>0.2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>48</th>\n","      <td>5.3</td>\n","      <td>3.7</td>\n","      <td>1.5</td>\n","      <td>0.2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>49</th>\n","      <td>5.0</td>\n","      <td>3.3</td>\n","      <td>1.4</td>\n","      <td>0.2</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    sepal length (cm)  sepal width (cm)  ...  petal width (cm)  target\n","0                 5.1               3.5  ...               0.2       0\n","1                 4.9               3.0  ...               0.2       0\n","2                 4.7               3.2  ...               0.2       0\n","3                 4.6               3.1  ...               0.2       0\n","4                 5.0               3.6  ...               0.2       0\n","5                 5.4               3.9  ...               0.4       0\n","6                 4.6               3.4  ...               0.3       0\n","7                 5.0               3.4  ...               0.2       0\n","8                 4.4               2.9  ...               0.2       0\n","9                 4.9               3.1  ...               0.1       0\n","10                5.4               3.7  ...               0.2       0\n","11                4.8               3.4  ...               0.2       0\n","12                4.8               3.0  ...               0.1       0\n","13                4.3               3.0  ...               0.1       0\n","14                5.8               4.0  ...               0.2       0\n","15                5.7               4.4  ...               0.4       0\n","16                5.4               3.9  ...               0.4       0\n","17                5.1               3.5  ...               0.3       0\n","18                5.7               3.8  ...               0.3       0\n","19                5.1               3.8  ...               0.3       0\n","20                5.4               3.4  ...               0.2       0\n","21                5.1               3.7  ...               0.4       0\n","22                4.6               3.6  ...               0.2       0\n","23                5.1               3.3  ...               0.5       0\n","24                4.8               3.4  ...               0.2       0\n","25                5.0               3.0  ...               0.2       0\n","26                5.0               3.4  ...               0.4       0\n","27                5.2               3.5  ...               0.2       0\n","28                5.2               3.4  ...               0.2       0\n","29                4.7               3.2  ...               0.2       0\n","30                4.8               3.1  ...               0.2       0\n","31                5.4               3.4  ...               0.4       0\n","32                5.2               4.1  ...               0.1       0\n","33                5.5               4.2  ...               0.2       0\n","34                4.9               3.1  ...               0.2       0\n","35                5.0               3.2  ...               0.2       0\n","36                5.5               3.5  ...               0.2       0\n","37                4.9               3.6  ...               0.1       0\n","38                4.4               3.0  ...               0.2       0\n","39                5.1               3.4  ...               0.2       0\n","40                5.0               3.5  ...               0.3       0\n","41                4.5               2.3  ...               0.3       0\n","42                4.4               3.2  ...               0.2       0\n","43                5.0               3.5  ...               0.6       0\n","44                5.1               3.8  ...               0.4       0\n","45                4.8               3.0  ...               0.3       0\n","46                5.1               3.8  ...               0.2       0\n","47                4.6               3.2  ...               0.2       0\n","48                5.3               3.7  ...               0.2       0\n","49                5.0               3.3  ...               0.2       0\n","\n","[50 rows x 5 columns]"]},"metadata":{"tags":[]},"execution_count":404}]},{"cell_type":"code","metadata":{"id":"UQtAlnsnvaSK","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1597407421213,"user_tz":-330,"elapsed":1181,"user":{"displayName":"john wickson","photoUrl":"","userId":"02886435677777830514"}},"outputId":"cd648c96-9e1a-482c-a682-c27f6d850b6a"},"source":["df1=df[df.target==1]\n","df1"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sepal length (cm)</th>\n","      <th>sepal width (cm)</th>\n","      <th>petal length (cm)</th>\n","      <th>petal width (cm)</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>50</th>\n","      <td>7.0</td>\n","      <td>3.2</td>\n","      <td>4.7</td>\n","      <td>1.4</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>51</th>\n","      <td>6.4</td>\n","      <td>3.2</td>\n","      <td>4.5</td>\n","      <td>1.5</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>52</th>\n","      <td>6.9</td>\n","      <td>3.1</td>\n","      <td>4.9</td>\n","      <td>1.5</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>53</th>\n","      <td>5.5</td>\n","      <td>2.3</td>\n","      <td>4.0</td>\n","      <td>1.3</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>54</th>\n","      <td>6.5</td>\n","      <td>2.8</td>\n","      <td>4.6</td>\n","      <td>1.5</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>55</th>\n","      <td>5.7</td>\n","      <td>2.8</td>\n","      <td>4.5</td>\n","      <td>1.3</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>56</th>\n","      <td>6.3</td>\n","      <td>3.3</td>\n","      <td>4.7</td>\n","      <td>1.6</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>57</th>\n","      <td>4.9</td>\n","      <td>2.4</td>\n","      <td>3.3</td>\n","      <td>1.0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>58</th>\n","      <td>6.6</td>\n","      <td>2.9</td>\n","      <td>4.6</td>\n","      <td>1.3</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>59</th>\n","      <td>5.2</td>\n","      <td>2.7</td>\n","      <td>3.9</td>\n","      <td>1.4</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>60</th>\n","      <td>5.0</td>\n","      <td>2.0</td>\n","      <td>3.5</td>\n","      <td>1.0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>61</th>\n","      <td>5.9</td>\n","      <td>3.0</td>\n","      <td>4.2</td>\n","      <td>1.5</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>62</th>\n","      <td>6.0</td>\n","      <td>2.2</td>\n","      <td>4.0</td>\n","      <td>1.0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>63</th>\n","      <td>6.1</td>\n","      <td>2.9</td>\n","      <td>4.7</td>\n","      <td>1.4</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>64</th>\n","      <td>5.6</td>\n","      <td>2.9</td>\n","      <td>3.6</td>\n","      <td>1.3</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>65</th>\n","      <td>6.7</td>\n","      <td>3.1</td>\n","      <td>4.4</td>\n","      <td>1.4</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>66</th>\n","      <td>5.6</td>\n","      <td>3.0</td>\n","      <td>4.5</td>\n","      <td>1.5</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>67</th>\n","      <td>5.8</td>\n","      <td>2.7</td>\n","      <td>4.1</td>\n","      <td>1.0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>68</th>\n","      <td>6.2</td>\n","      <td>2.2</td>\n","      <td>4.5</td>\n","      <td>1.5</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>69</th>\n","      <td>5.6</td>\n","      <td>2.5</td>\n","      <td>3.9</td>\n","      <td>1.1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>70</th>\n","      <td>5.9</td>\n","      <td>3.2</td>\n","      <td>4.8</td>\n","      <td>1.8</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>71</th>\n","      <td>6.1</td>\n","      <td>2.8</td>\n","      <td>4.0</td>\n","      <td>1.3</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>72</th>\n","      <td>6.3</td>\n","      <td>2.5</td>\n","      <td>4.9</td>\n","      <td>1.5</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>73</th>\n","      <td>6.1</td>\n","      <td>2.8</td>\n","      <td>4.7</td>\n","      <td>1.2</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>74</th>\n","      <td>6.4</td>\n","      <td>2.9</td>\n","      <td>4.3</td>\n","      <td>1.3</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>75</th>\n","      <td>6.6</td>\n","      <td>3.0</td>\n","      <td>4.4</td>\n","      <td>1.4</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>76</th>\n","      <td>6.8</td>\n","      <td>2.8</td>\n","      <td>4.8</td>\n","      <td>1.4</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>77</th>\n","      <td>6.7</td>\n","      <td>3.0</td>\n","      <td>5.0</td>\n","      <td>1.7</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>78</th>\n","      <td>6.0</td>\n","      <td>2.9</td>\n","      <td>4.5</td>\n","      <td>1.5</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>79</th>\n","      <td>5.7</td>\n","      <td>2.6</td>\n","      <td>3.5</td>\n","      <td>1.0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>80</th>\n","      <td>5.5</td>\n","      <td>2.4</td>\n","      <td>3.8</td>\n","      <td>1.1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>81</th>\n","      <td>5.5</td>\n","      <td>2.4</td>\n","      <td>3.7</td>\n","      <td>1.0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>82</th>\n","      <td>5.8</td>\n","      <td>2.7</td>\n","      <td>3.9</td>\n","      <td>1.2</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>83</th>\n","      <td>6.0</td>\n","      <td>2.7</td>\n","      <td>5.1</td>\n","      <td>1.6</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>84</th>\n","      <td>5.4</td>\n","      <td>3.0</td>\n","      <td>4.5</td>\n","      <td>1.5</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>85</th>\n","      <td>6.0</td>\n","      <td>3.4</td>\n","      <td>4.5</td>\n","      <td>1.6</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>86</th>\n","      <td>6.7</td>\n","      <td>3.1</td>\n","      <td>4.7</td>\n","      <td>1.5</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>87</th>\n","      <td>6.3</td>\n","      <td>2.3</td>\n","      <td>4.4</td>\n","      <td>1.3</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>88</th>\n","      <td>5.6</td>\n","      <td>3.0</td>\n","      <td>4.1</td>\n","      <td>1.3</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>89</th>\n","      <td>5.5</td>\n","      <td>2.5</td>\n","      <td>4.0</td>\n","      <td>1.3</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>90</th>\n","      <td>5.5</td>\n","      <td>2.6</td>\n","      <td>4.4</td>\n","      <td>1.2</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>91</th>\n","      <td>6.1</td>\n","      <td>3.0</td>\n","      <td>4.6</td>\n","      <td>1.4</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>92</th>\n","      <td>5.8</td>\n","      <td>2.6</td>\n","      <td>4.0</td>\n","      <td>1.2</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>93</th>\n","      <td>5.0</td>\n","      <td>2.3</td>\n","      <td>3.3</td>\n","      <td>1.0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>94</th>\n","      <td>5.6</td>\n","      <td>2.7</td>\n","      <td>4.2</td>\n","      <td>1.3</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>95</th>\n","      <td>5.7</td>\n","      <td>3.0</td>\n","      <td>4.2</td>\n","      <td>1.2</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>96</th>\n","      <td>5.7</td>\n","      <td>2.9</td>\n","      <td>4.2</td>\n","      <td>1.3</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>97</th>\n","      <td>6.2</td>\n","      <td>2.9</td>\n","      <td>4.3</td>\n","      <td>1.3</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>98</th>\n","      <td>5.1</td>\n","      <td>2.5</td>\n","      <td>3.0</td>\n","      <td>1.1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>99</th>\n","      <td>5.7</td>\n","      <td>2.8</td>\n","      <td>4.1</td>\n","      <td>1.3</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    sepal length (cm)  sepal width (cm)  ...  petal width (cm)  target\n","50                7.0               3.2  ...               1.4       1\n","51                6.4               3.2  ...               1.5       1\n","52                6.9               3.1  ...               1.5       1\n","53                5.5               2.3  ...               1.3       1\n","54                6.5               2.8  ...               1.5       1\n","55                5.7               2.8  ...               1.3       1\n","56                6.3               3.3  ...               1.6       1\n","57                4.9               2.4  ...               1.0       1\n","58                6.6               2.9  ...               1.3       1\n","59                5.2               2.7  ...               1.4       1\n","60                5.0               2.0  ...               1.0       1\n","61                5.9               3.0  ...               1.5       1\n","62                6.0               2.2  ...               1.0       1\n","63                6.1               2.9  ...               1.4       1\n","64                5.6               2.9  ...               1.3       1\n","65                6.7               3.1  ...               1.4       1\n","66                5.6               3.0  ...               1.5       1\n","67                5.8               2.7  ...               1.0       1\n","68                6.2               2.2  ...               1.5       1\n","69                5.6               2.5  ...               1.1       1\n","70                5.9               3.2  ...               1.8       1\n","71                6.1               2.8  ...               1.3       1\n","72                6.3               2.5  ...               1.5       1\n","73                6.1               2.8  ...               1.2       1\n","74                6.4               2.9  ...               1.3       1\n","75                6.6               3.0  ...               1.4       1\n","76                6.8               2.8  ...               1.4       1\n","77                6.7               3.0  ...               1.7       1\n","78                6.0               2.9  ...               1.5       1\n","79                5.7               2.6  ...               1.0       1\n","80                5.5               2.4  ...               1.1       1\n","81                5.5               2.4  ...               1.0       1\n","82                5.8               2.7  ...               1.2       1\n","83                6.0               2.7  ...               1.6       1\n","84                5.4               3.0  ...               1.5       1\n","85                6.0               3.4  ...               1.6       1\n","86                6.7               3.1  ...               1.5       1\n","87                6.3               2.3  ...               1.3       1\n","88                5.6               3.0  ...               1.3       1\n","89                5.5               2.5  ...               1.3       1\n","90                5.5               2.6  ...               1.2       1\n","91                6.1               3.0  ...               1.4       1\n","92                5.8               2.6  ...               1.2       1\n","93                5.0               2.3  ...               1.0       1\n","94                5.6               2.7  ...               1.3       1\n","95                5.7               3.0  ...               1.2       1\n","96                5.7               2.9  ...               1.3       1\n","97                6.2               2.9  ...               1.3       1\n","98                5.1               2.5  ...               1.1       1\n","99                5.7               2.8  ...               1.3       1\n","\n","[50 rows x 5 columns]"]},"metadata":{"tags":[]},"execution_count":405}]},{"cell_type":"code","metadata":{"id":"UHeVvwEyvhng","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1597407421693,"user_tz":-330,"elapsed":1633,"user":{"displayName":"john wickson","photoUrl":"","userId":"02886435677777830514"}},"outputId":"03a7cc32-9727-4697-9927-c6ca380343e4"},"source":["df2=df[df.target==2]\n","df2"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sepal length (cm)</th>\n","      <th>sepal width (cm)</th>\n","      <th>petal length (cm)</th>\n","      <th>petal width (cm)</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>100</th>\n","      <td>6.3</td>\n","      <td>3.3</td>\n","      <td>6.0</td>\n","      <td>2.5</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>101</th>\n","      <td>5.8</td>\n","      <td>2.7</td>\n","      <td>5.1</td>\n","      <td>1.9</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>102</th>\n","      <td>7.1</td>\n","      <td>3.0</td>\n","      <td>5.9</td>\n","      <td>2.1</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>103</th>\n","      <td>6.3</td>\n","      <td>2.9</td>\n","      <td>5.6</td>\n","      <td>1.8</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>104</th>\n","      <td>6.5</td>\n","      <td>3.0</td>\n","      <td>5.8</td>\n","      <td>2.2</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>105</th>\n","      <td>7.6</td>\n","      <td>3.0</td>\n","      <td>6.6</td>\n","      <td>2.1</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>106</th>\n","      <td>4.9</td>\n","      <td>2.5</td>\n","      <td>4.5</td>\n","      <td>1.7</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>107</th>\n","      <td>7.3</td>\n","      <td>2.9</td>\n","      <td>6.3</td>\n","      <td>1.8</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>108</th>\n","      <td>6.7</td>\n","      <td>2.5</td>\n","      <td>5.8</td>\n","      <td>1.8</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>109</th>\n","      <td>7.2</td>\n","      <td>3.6</td>\n","      <td>6.1</td>\n","      <td>2.5</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>110</th>\n","      <td>6.5</td>\n","      <td>3.2</td>\n","      <td>5.1</td>\n","      <td>2.0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>111</th>\n","      <td>6.4</td>\n","      <td>2.7</td>\n","      <td>5.3</td>\n","      <td>1.9</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>112</th>\n","      <td>6.8</td>\n","      <td>3.0</td>\n","      <td>5.5</td>\n","      <td>2.1</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>113</th>\n","      <td>5.7</td>\n","      <td>2.5</td>\n","      <td>5.0</td>\n","      <td>2.0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>114</th>\n","      <td>5.8</td>\n","      <td>2.8</td>\n","      <td>5.1</td>\n","      <td>2.4</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>115</th>\n","      <td>6.4</td>\n","      <td>3.2</td>\n","      <td>5.3</td>\n","      <td>2.3</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>116</th>\n","      <td>6.5</td>\n","      <td>3.0</td>\n","      <td>5.5</td>\n","      <td>1.8</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>117</th>\n","      <td>7.7</td>\n","      <td>3.8</td>\n","      <td>6.7</td>\n","      <td>2.2</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>118</th>\n","      <td>7.7</td>\n","      <td>2.6</td>\n","      <td>6.9</td>\n","      <td>2.3</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>119</th>\n","      <td>6.0</td>\n","      <td>2.2</td>\n","      <td>5.0</td>\n","      <td>1.5</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>120</th>\n","      <td>6.9</td>\n","      <td>3.2</td>\n","      <td>5.7</td>\n","      <td>2.3</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>121</th>\n","      <td>5.6</td>\n","      <td>2.8</td>\n","      <td>4.9</td>\n","      <td>2.0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>122</th>\n","      <td>7.7</td>\n","      <td>2.8</td>\n","      <td>6.7</td>\n","      <td>2.0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>123</th>\n","      <td>6.3</td>\n","      <td>2.7</td>\n","      <td>4.9</td>\n","      <td>1.8</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>124</th>\n","      <td>6.7</td>\n","      <td>3.3</td>\n","      <td>5.7</td>\n","      <td>2.1</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>125</th>\n","      <td>7.2</td>\n","      <td>3.2</td>\n","      <td>6.0</td>\n","      <td>1.8</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>126</th>\n","      <td>6.2</td>\n","      <td>2.8</td>\n","      <td>4.8</td>\n","      <td>1.8</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>127</th>\n","      <td>6.1</td>\n","      <td>3.0</td>\n","      <td>4.9</td>\n","      <td>1.8</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>128</th>\n","      <td>6.4</td>\n","      <td>2.8</td>\n","      <td>5.6</td>\n","      <td>2.1</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>129</th>\n","      <td>7.2</td>\n","      <td>3.0</td>\n","      <td>5.8</td>\n","      <td>1.6</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>130</th>\n","      <td>7.4</td>\n","      <td>2.8</td>\n","      <td>6.1</td>\n","      <td>1.9</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>131</th>\n","      <td>7.9</td>\n","      <td>3.8</td>\n","      <td>6.4</td>\n","      <td>2.0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>132</th>\n","      <td>6.4</td>\n","      <td>2.8</td>\n","      <td>5.6</td>\n","      <td>2.2</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>133</th>\n","      <td>6.3</td>\n","      <td>2.8</td>\n","      <td>5.1</td>\n","      <td>1.5</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>134</th>\n","      <td>6.1</td>\n","      <td>2.6</td>\n","      <td>5.6</td>\n","      <td>1.4</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>135</th>\n","      <td>7.7</td>\n","      <td>3.0</td>\n","      <td>6.1</td>\n","      <td>2.3</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>136</th>\n","      <td>6.3</td>\n","      <td>3.4</td>\n","      <td>5.6</td>\n","      <td>2.4</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>137</th>\n","      <td>6.4</td>\n","      <td>3.1</td>\n","      <td>5.5</td>\n","      <td>1.8</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>138</th>\n","      <td>6.0</td>\n","      <td>3.0</td>\n","      <td>4.8</td>\n","      <td>1.8</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>139</th>\n","      <td>6.9</td>\n","      <td>3.1</td>\n","      <td>5.4</td>\n","      <td>2.1</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>140</th>\n","      <td>6.7</td>\n","      <td>3.1</td>\n","      <td>5.6</td>\n","      <td>2.4</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>141</th>\n","      <td>6.9</td>\n","      <td>3.1</td>\n","      <td>5.1</td>\n","      <td>2.3</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>142</th>\n","      <td>5.8</td>\n","      <td>2.7</td>\n","      <td>5.1</td>\n","      <td>1.9</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>143</th>\n","      <td>6.8</td>\n","      <td>3.2</td>\n","      <td>5.9</td>\n","      <td>2.3</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>144</th>\n","      <td>6.7</td>\n","      <td>3.3</td>\n","      <td>5.7</td>\n","      <td>2.5</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>145</th>\n","      <td>6.7</td>\n","      <td>3.0</td>\n","      <td>5.2</td>\n","      <td>2.3</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>146</th>\n","      <td>6.3</td>\n","      <td>2.5</td>\n","      <td>5.0</td>\n","      <td>1.9</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>147</th>\n","      <td>6.5</td>\n","      <td>3.0</td>\n","      <td>5.2</td>\n","      <td>2.0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>148</th>\n","      <td>6.2</td>\n","      <td>3.4</td>\n","      <td>5.4</td>\n","      <td>2.3</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>149</th>\n","      <td>5.9</td>\n","      <td>3.0</td>\n","      <td>5.1</td>\n","      <td>1.8</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     sepal length (cm)  sepal width (cm)  ...  petal width (cm)  target\n","100                6.3               3.3  ...               2.5       2\n","101                5.8               2.7  ...               1.9       2\n","102                7.1               3.0  ...               2.1       2\n","103                6.3               2.9  ...               1.8       2\n","104                6.5               3.0  ...               2.2       2\n","105                7.6               3.0  ...               2.1       2\n","106                4.9               2.5  ...               1.7       2\n","107                7.3               2.9  ...               1.8       2\n","108                6.7               2.5  ...               1.8       2\n","109                7.2               3.6  ...               2.5       2\n","110                6.5               3.2  ...               2.0       2\n","111                6.4               2.7  ...               1.9       2\n","112                6.8               3.0  ...               2.1       2\n","113                5.7               2.5  ...               2.0       2\n","114                5.8               2.8  ...               2.4       2\n","115                6.4               3.2  ...               2.3       2\n","116                6.5               3.0  ...               1.8       2\n","117                7.7               3.8  ...               2.2       2\n","118                7.7               2.6  ...               2.3       2\n","119                6.0               2.2  ...               1.5       2\n","120                6.9               3.2  ...               2.3       2\n","121                5.6               2.8  ...               2.0       2\n","122                7.7               2.8  ...               2.0       2\n","123                6.3               2.7  ...               1.8       2\n","124                6.7               3.3  ...               2.1       2\n","125                7.2               3.2  ...               1.8       2\n","126                6.2               2.8  ...               1.8       2\n","127                6.1               3.0  ...               1.8       2\n","128                6.4               2.8  ...               2.1       2\n","129                7.2               3.0  ...               1.6       2\n","130                7.4               2.8  ...               1.9       2\n","131                7.9               3.8  ...               2.0       2\n","132                6.4               2.8  ...               2.2       2\n","133                6.3               2.8  ...               1.5       2\n","134                6.1               2.6  ...               1.4       2\n","135                7.7               3.0  ...               2.3       2\n","136                6.3               3.4  ...               2.4       2\n","137                6.4               3.1  ...               1.8       2\n","138                6.0               3.0  ...               1.8       2\n","139                6.9               3.1  ...               2.1       2\n","140                6.7               3.1  ...               2.4       2\n","141                6.9               3.1  ...               2.3       2\n","142                5.8               2.7  ...               1.9       2\n","143                6.8               3.2  ...               2.3       2\n","144                6.7               3.3  ...               2.5       2\n","145                6.7               3.0  ...               2.3       2\n","146                6.3               2.5  ...               1.9       2\n","147                6.5               3.0  ...               2.0       2\n","148                6.2               3.4  ...               2.3       2\n","149                5.9               3.0  ...               1.8       2\n","\n","[50 rows x 5 columns]"]},"metadata":{"tags":[]},"execution_count":406}]},{"cell_type":"code","metadata":{"id":"IfMxjVVjvrrs","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":370},"executionInfo":{"status":"ok","timestamp":1597407421695,"user_tz":-330,"elapsed":1609,"user":{"displayName":"john wickson","photoUrl":"","userId":"02886435677777830514"}},"outputId":"58b3b012-2396-4855-9c0b-04cf4f97451c"},"source":["import matplotlib.pyplot as plt\n","plt.xlabel('sepal length (cm)')\n","plt.ylabel('sepal width (cm)\t')\n","plt.scatter(df0.iloc[:,0:1],df0.iloc[:,1:2],color='red',marker='*')\n","plt.scatter(df1.iloc[:,0:1],df1.iloc[:,1:2],color='blue',marker='*')"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.collections.PathCollection at 0x7f7c21ade3c8>"]},"metadata":{"tags":[]},"execution_count":407},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 9 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 9 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n"],"name":"stderr"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"nALWdgc-yjwI","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":366},"executionInfo":{"status":"ok","timestamp":1597407421698,"user_tz":-330,"elapsed":1597,"user":{"displayName":"john wickson","photoUrl":"","userId":"02886435677777830514"}},"outputId":"769adce2-6694-44fa-ed32-d338f38b184a"},"source":["import matplotlib.pyplot as plt\n","plt.xlabel('petal length (cm)')\n","plt.ylabel('petal width (cm)\t')\n","plt.scatter(df0.iloc[:,2],df0.iloc[:,3],color='red',marker='*')\n","plt.scatter(df1.iloc[:,2],df1.iloc[:,3],color='blue',marker='*')"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.collections.PathCollection at 0x7f7c21abd3c8>"]},"metadata":{"tags":[]},"execution_count":408},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 9 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 9 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n"],"name":"stderr"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"JVIFQZerzFc7","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":402},"executionInfo":{"status":"ok","timestamp":1597407421699,"user_tz":-330,"elapsed":1583,"user":{"displayName":"john wickson","photoUrl":"","userId":"02886435677777830514"}},"outputId":"672076a9-ffc3-465d-c1d1-a2f60e34b95d"},"source":["x=df.drop('target',axis='columns')\n","x"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sepal length (cm)</th>\n","      <th>sepal width (cm)</th>\n","      <th>petal length (cm)</th>\n","      <th>petal width (cm)</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>5.1</td>\n","      <td>3.5</td>\n","      <td>1.4</td>\n","      <td>0.2</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>4.9</td>\n","      <td>3.0</td>\n","      <td>1.4</td>\n","      <td>0.2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>4.7</td>\n","      <td>3.2</td>\n","      <td>1.3</td>\n","      <td>0.2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4.6</td>\n","      <td>3.1</td>\n","      <td>1.5</td>\n","      <td>0.2</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5.0</td>\n","      <td>3.6</td>\n","      <td>1.4</td>\n","      <td>0.2</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>145</th>\n","      <td>6.7</td>\n","      <td>3.0</td>\n","      <td>5.2</td>\n","      <td>2.3</td>\n","    </tr>\n","    <tr>\n","      <th>146</th>\n","      <td>6.3</td>\n","      <td>2.5</td>\n","      <td>5.0</td>\n","      <td>1.9</td>\n","    </tr>\n","    <tr>\n","      <th>147</th>\n","      <td>6.5</td>\n","      <td>3.0</td>\n","      <td>5.2</td>\n","      <td>2.0</td>\n","    </tr>\n","    <tr>\n","      <th>148</th>\n","      <td>6.2</td>\n","      <td>3.4</td>\n","      <td>5.4</td>\n","      <td>2.3</td>\n","    </tr>\n","    <tr>\n","      <th>149</th>\n","      <td>5.9</td>\n","      <td>3.0</td>\n","      <td>5.1</td>\n","      <td>1.8</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>150 rows × 4 columns</p>\n","</div>"],"text/plain":["     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n","0                  5.1               3.5                1.4               0.2\n","1                  4.9               3.0                1.4               0.2\n","2                  4.7               3.2                1.3               0.2\n","3                  4.6               3.1                1.5               0.2\n","4                  5.0               3.6                1.4               0.2\n","..                 ...               ...                ...               ...\n","145                6.7               3.0                5.2               2.3\n","146                6.3               2.5                5.0               1.9\n","147                6.5               3.0                5.2               2.0\n","148                6.2               3.4                5.4               2.3\n","149                5.9               3.0                5.1               1.8\n","\n","[150 rows x 4 columns]"]},"metadata":{"tags":[]},"execution_count":409}]},{"cell_type":"code","metadata":{"id":"2ZWach8SzTmW","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":134},"executionInfo":{"status":"ok","timestamp":1597407421701,"user_tz":-330,"elapsed":1574,"user":{"displayName":"john wickson","photoUrl":"","userId":"02886435677777830514"}},"outputId":"5241dec9-fe32-47f5-beb4-6f241292d434"},"source":["y"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n","       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n","       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"]},"metadata":{"tags":[]},"execution_count":410}]},{"cell_type":"code","metadata":{"id":"au-fvZfqy7Yj","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1597407421702,"user_tz":-330,"elapsed":1566,"user":{"displayName":"john wickson","photoUrl":"","userId":"02886435677777830514"}},"outputId":"4091e81e-fecd-4a50-b21f-b0726e207c76"},"source":["from sklearn.model_selection import train_test_split\n","x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=2)\n","from sklearn.svm import SVC\n","model=SVC(C=5)\n","model.fit(x_train,y_train)\n","print(model.score(x_test,y_test))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"smIRszQa0HfT","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":50},"executionInfo":{"status":"ok","timestamp":1597407421703,"user_tz":-330,"elapsed":1558,"user":{"displayName":"john wickson","photoUrl":"","userId":"02886435677777830514"}},"outputId":"c76e9b96-55e5-484a-c6ff-69fb6622f08b"},"source":["model.predict(x_test)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0, 0, 2, 0, 0, 2, 0, 2, 2, 0, 0, 0, 0, 0, 1, 1, 0, 1, 2, 1, 1, 1,\n","       2, 1, 1, 0, 0, 2, 0, 2])"]},"metadata":{"tags":[]},"execution_count":412}]},{"cell_type":"code","metadata":{"id":"n99fIhFD0K8X","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":50},"executionInfo":{"status":"ok","timestamp":1597407421704,"user_tz":-330,"elapsed":1550,"user":{"displayName":"john wickson","photoUrl":"","userId":"02886435677777830514"}},"outputId":"28d0df03-19c3-4bb0-cc6e-b708572fea76"},"source":["y_test"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0, 0, 2, 0, 0, 2, 0, 2, 2, 0, 0, 0, 0, 0, 1, 1, 0, 1, 2, 1, 1, 1,\n","       2, 1, 1, 0, 0, 2, 0, 2])"]},"metadata":{"tags":[]},"execution_count":413}]},{"cell_type":"code","metadata":{"id":"Fhg4Spwj7JNx","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1597407803087,"user_tz":-330,"elapsed":1014,"user":{"displayName":"john wickson","photoUrl":"","userId":"02886435677777830514"}},"outputId":"c3090ebd-c53a-4959-fa92-f381d3b90416"},"source":["help(SVC())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Help on SVC in module sklearn.svm._classes object:\n","\n","class SVC(sklearn.svm._base.BaseSVC)\n"," |  C-Support Vector Classification.\n"," |  \n"," |  The implementation is based on libsvm. The fit time scales at least\n"," |  quadratically with the number of samples and may be impractical\n"," |  beyond tens of thousands of samples. For large datasets\n"," |  consider using :class:`sklearn.svm.LinearSVC` or\n"," |  :class:`sklearn.linear_model.SGDClassifier` instead, possibly after a\n"," |  :class:`sklearn.kernel_approximation.Nystroem` transformer.\n"," |  \n"," |  The multiclass support is handled according to a one-vs-one scheme.\n"," |  \n"," |  For details on the precise mathematical formulation of the provided\n"," |  kernel functions and how `gamma`, `coef0` and `degree` affect each\n"," |  other, see the corresponding section in the narrative documentation:\n"," |  :ref:`svm_kernels`.\n"," |  \n"," |  Read more in the :ref:`User Guide <svm_classification>`.\n"," |  \n"," |  Parameters\n"," |  ----------\n"," |  C : float, optional (default=1.0)\n"," |      Regularization parameter. The strength of the regularization is\n"," |      inversely proportional to C. Must be strictly positive. The penalty\n"," |      is a squared l2 penalty.\n"," |  \n"," |  kernel : string, optional (default='rbf')\n"," |      Specifies the kernel type to be used in the algorithm.\n"," |      It must be one of 'linear', 'poly', 'rbf', 'sigmoid', 'precomputed' or\n"," |      a callable.\n"," |      If none is given, 'rbf' will be used. If a callable is given it is\n"," |      used to pre-compute the kernel matrix from data matrices; that matrix\n"," |      should be an array of shape ``(n_samples, n_samples)``.\n"," |  \n"," |  degree : int, optional (default=3)\n"," |      Degree of the polynomial kernel function ('poly').\n"," |      Ignored by all other kernels.\n"," |  \n"," |  gamma : {'scale', 'auto'} or float, optional (default='scale')\n"," |      Kernel coefficient for 'rbf', 'poly' and 'sigmoid'.\n"," |  \n"," |      - if ``gamma='scale'`` (default) is passed then it uses\n"," |        1 / (n_features * X.var()) as value of gamma,\n"," |      - if 'auto', uses 1 / n_features.\n"," |  \n"," |      .. versionchanged:: 0.22\n"," |         The default value of ``gamma`` changed from 'auto' to 'scale'.\n"," |  \n"," |  coef0 : float, optional (default=0.0)\n"," |      Independent term in kernel function.\n"," |      It is only significant in 'poly' and 'sigmoid'.\n"," |  \n"," |  shrinking : boolean, optional (default=True)\n"," |      Whether to use the shrinking heuristic.\n"," |  \n"," |  probability : boolean, optional (default=False)\n"," |      Whether to enable probability estimates. This must be enabled prior\n"," |      to calling `fit`, will slow down that method as it internally uses\n"," |      5-fold cross-validation, and `predict_proba` may be inconsistent with\n"," |      `predict`. Read more in the :ref:`User Guide <scores_probabilities>`.\n"," |  \n"," |  tol : float, optional (default=1e-3)\n"," |      Tolerance for stopping criterion.\n"," |  \n"," |  cache_size : float, optional\n"," |      Specify the size of the kernel cache (in MB).\n"," |  \n"," |  class_weight : {dict, 'balanced'}, optional\n"," |      Set the parameter C of class i to class_weight[i]*C for\n"," |      SVC. If not given, all classes are supposed to have\n"," |      weight one.\n"," |      The \"balanced\" mode uses the values of y to automatically adjust\n"," |      weights inversely proportional to class frequencies in the input data\n"," |      as ``n_samples / (n_classes * np.bincount(y))``\n"," |  \n"," |  verbose : bool, default: False\n"," |      Enable verbose output. Note that this setting takes advantage of a\n"," |      per-process runtime setting in libsvm that, if enabled, may not work\n"," |      properly in a multithreaded context.\n"," |  \n"," |  max_iter : int, optional (default=-1)\n"," |      Hard limit on iterations within solver, or -1 for no limit.\n"," |  \n"," |  decision_function_shape : 'ovo', 'ovr', default='ovr'\n"," |      Whether to return a one-vs-rest ('ovr') decision function of shape\n"," |      (n_samples, n_classes) as all other classifiers, or the original\n"," |      one-vs-one ('ovo') decision function of libsvm which has shape\n"," |      (n_samples, n_classes * (n_classes - 1) / 2). However, one-vs-one\n"," |      ('ovo') is always used as multi-class strategy.\n"," |  \n"," |      .. versionchanged:: 0.19\n"," |          decision_function_shape is 'ovr' by default.\n"," |  \n"," |      .. versionadded:: 0.17\n"," |         *decision_function_shape='ovr'* is recommended.\n"," |  \n"," |      .. versionchanged:: 0.17\n"," |         Deprecated *decision_function_shape='ovo' and None*.\n"," |  \n"," |  break_ties : bool, optional (default=False)\n"," |      If true, ``decision_function_shape='ovr'``, and number of classes > 2,\n"," |      :term:`predict` will break ties according to the confidence values of\n"," |      :term:`decision_function`; otherwise the first class among the tied\n"," |      classes is returned. Please note that breaking ties comes at a\n"," |      relatively high computational cost compared to a simple predict.\n"," |  \n"," |      .. versionadded:: 0.22\n"," |  \n"," |  random_state : int, RandomState instance or None, optional (default=None)\n"," |      The seed of the pseudo random number generator used when shuffling\n"," |      the data for probability estimates. If int, random_state is the\n"," |      seed used by the random number generator; If RandomState instance,\n"," |      random_state is the random number generator; If None, the random\n"," |      number generator is the RandomState instance used by `np.random`.\n"," |  \n"," |  Attributes\n"," |  ----------\n"," |  support_ : array-like of shape (n_SV)\n"," |      Indices of support vectors.\n"," |  \n"," |  support_vectors_ : array-like of shape (n_SV, n_features)\n"," |      Support vectors.\n"," |  \n"," |  n_support_ : array-like, dtype=int32, shape = [n_class]\n"," |      Number of support vectors for each class.\n"," |  \n"," |  dual_coef_ : array, shape = [n_class-1, n_SV]\n"," |      Coefficients of the support vector in the decision function.\n"," |      For multiclass, coefficient for all 1-vs-1 classifiers.\n"," |      The layout of the coefficients in the multiclass case is somewhat\n"," |      non-trivial. See the section about multi-class classification in the\n"," |      SVM section of the User Guide for details.\n"," |  \n"," |  coef_ : array, shape = [n_class * (n_class-1) / 2, n_features]\n"," |      Weights assigned to the features (coefficients in the primal\n"," |      problem). This is only available in the case of a linear kernel.\n"," |  \n"," |      `coef_` is a readonly property derived from `dual_coef_` and\n"," |      `support_vectors_`.\n"," |  \n"," |  intercept_ : ndarray of shape (n_class * (n_class-1) / 2,)\n"," |      Constants in decision function.\n"," |  \n"," |  fit_status_ : int\n"," |      0 if correctly fitted, 1 otherwise (will raise warning)\n"," |  \n"," |  classes_ : array of shape (n_classes,)\n"," |      The classes labels.\n"," |  \n"," |  probA_ : array, shape = [n_class * (n_class-1) / 2]\n"," |  probB_ : array, shape = [n_class * (n_class-1) / 2]\n"," |      If `probability=True`, it corresponds to the parameters learned in\n"," |      Platt scaling to produce probability estimates from decision values.\n"," |      If `probability=False`, it's an empty array. Platt scaling uses the\n"," |      logistic function\n"," |      ``1 / (1 + exp(decision_value * probA_ + probB_))``\n"," |      where ``probA_`` and ``probB_`` are learned from the dataset [2]_. For\n"," |      more information on the multiclass case and training procedure see\n"," |      section 8 of [1]_.\n"," |  \n"," |  class_weight_ : ndarray of shape (n_class,)\n"," |      Multipliers of parameter C for each class.\n"," |      Computed based on the ``class_weight`` parameter.\n"," |  \n"," |  shape_fit_ : tuple of int of shape (n_dimensions_of_X,)\n"," |      Array dimensions of training vector ``X``.\n"," |  \n"," |  Examples\n"," |  --------\n"," |  >>> import numpy as np\n"," |  >>> X = np.array([[-1, -1], [-2, -1], [1, 1], [2, 1]])\n"," |  >>> y = np.array([1, 1, 2, 2])\n"," |  >>> from sklearn.svm import SVC\n"," |  >>> clf = SVC(gamma='auto')\n"," |  >>> clf.fit(X, y)\n"," |  SVC(gamma='auto')\n"," |  >>> print(clf.predict([[-0.8, -1]]))\n"," |  [1]\n"," |  \n"," |  See also\n"," |  --------\n"," |  SVR\n"," |      Support Vector Machine for Regression implemented using libsvm.\n"," |  \n"," |  LinearSVC\n"," |      Scalable Linear Support Vector Machine for classification\n"," |      implemented using liblinear. Check the See also section of\n"," |      LinearSVC for more comparison element.\n"," |  \n"," |  References\n"," |  ----------\n"," |  .. [1] `LIBSVM: A Library for Support Vector Machines\n"," |      <http://www.csie.ntu.edu.tw/~cjlin/papers/libsvm.pdf>`_\n"," |  \n"," |  .. [2] `Platt, John (1999). \"Probabilistic outputs for support vector\n"," |      machines and comparison to regularizedlikelihood methods.\"\n"," |      <http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.41.1639>`_\n"," |  \n"," |  Method resolution order:\n"," |      SVC\n"," |      sklearn.svm._base.BaseSVC\n"," |      sklearn.base.ClassifierMixin\n"," |      sklearn.svm._base.BaseLibSVM\n"," |      sklearn.base.BaseEstimator\n"," |      builtins.object\n"," |  \n"," |  Methods defined here:\n"," |  \n"," |  __init__(self, C=1.0, kernel='rbf', degree=3, gamma='scale', coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=-1, decision_function_shape='ovr', break_ties=False, random_state=None)\n"," |      Initialize self.  See help(type(self)) for accurate signature.\n"," |  \n"," |  ----------------------------------------------------------------------\n"," |  Data and other attributes defined here:\n"," |  \n"," |  __abstractmethods__ = frozenset()\n"," |  \n"," |  ----------------------------------------------------------------------\n"," |  Methods inherited from sklearn.svm._base.BaseSVC:\n"," |  \n"," |  decision_function(self, X)\n"," |      Evaluates the decision function for the samples in X.\n"," |      \n"," |      Parameters\n"," |      ----------\n"," |      X : array-like, shape (n_samples, n_features)\n"," |      \n"," |      Returns\n"," |      -------\n"," |      X : array-like, shape (n_samples, n_classes * (n_classes-1) / 2)\n"," |          Returns the decision function of the sample for each class\n"," |          in the model.\n"," |          If decision_function_shape='ovr', the shape is (n_samples,\n"," |          n_classes).\n"," |      \n"," |      Notes\n"," |      -----\n"," |      If decision_function_shape='ovo', the function values are proportional\n"," |      to the distance of the samples X to the separating hyperplane. If the\n"," |      exact distances are required, divide the function values by the norm of\n"," |      the weight vector (``coef_``). See also `this question\n"," |      <https://stats.stackexchange.com/questions/14876/\n"," |      interpreting-distance-from-hyperplane-in-svm>`_ for further details.\n"," |      If decision_function_shape='ovr', the decision function is a monotonic\n"," |      transformation of ovo decision function.\n"," |  \n"," |  predict(self, X)\n"," |      Perform classification on samples in X.\n"," |      \n"," |      For an one-class model, +1 or -1 is returned.\n"," |      \n"," |      Parameters\n"," |      ----------\n"," |      X : {array-like, sparse matrix}, shape (n_samples, n_features)\n"," |          For kernel=\"precomputed\", the expected shape of X is\n"," |          [n_samples_test, n_samples_train]\n"," |      \n"," |      Returns\n"," |      -------\n"," |      y_pred : array, shape (n_samples,)\n"," |          Class labels for samples in X.\n"," |  \n"," |  ----------------------------------------------------------------------\n"," |  Data descriptors inherited from sklearn.svm._base.BaseSVC:\n"," |  \n"," |  predict_log_proba\n"," |      Compute log probabilities of possible outcomes for samples in X.\n"," |      \n"," |      The model need to have probability information computed at training\n"," |      time: fit with attribute `probability` set to True.\n"," |      \n"," |      Parameters\n"," |      ----------\n"," |      X : array-like, shape (n_samples, n_features)\n"," |          For kernel=\"precomputed\", the expected shape of X is\n"," |          [n_samples_test, n_samples_train]\n"," |      \n"," |      Returns\n"," |      -------\n"," |      T : array-like, shape (n_samples, n_classes)\n"," |          Returns the log-probabilities of the sample for each class in\n"," |          the model. The columns correspond to the classes in sorted\n"," |          order, as they appear in the attribute :term:`classes_`.\n"," |      \n"," |      Notes\n"," |      -----\n"," |      The probability model is created using cross validation, so\n"," |      the results can be slightly different than those obtained by\n"," |      predict. Also, it will produce meaningless results on very small\n"," |      datasets.\n"," |  \n"," |  predict_proba\n"," |      Compute probabilities of possible outcomes for samples in X.\n"," |      \n"," |      The model need to have probability information computed at training\n"," |      time: fit with attribute `probability` set to True.\n"," |      \n"," |      Parameters\n"," |      ----------\n"," |      X : array-like, shape (n_samples, n_features)\n"," |          For kernel=\"precomputed\", the expected shape of X is\n"," |          [n_samples_test, n_samples_train]\n"," |      \n"," |      Returns\n"," |      -------\n"," |      T : array-like, shape (n_samples, n_classes)\n"," |          Returns the probability of the sample for each class in\n"," |          the model. The columns correspond to the classes in sorted\n"," |          order, as they appear in the attribute :term:`classes_`.\n"," |      \n"," |      Notes\n"," |      -----\n"," |      The probability model is created using cross validation, so\n"," |      the results can be slightly different than those obtained by\n"," |      predict. Also, it will produce meaningless results on very small\n"," |      datasets.\n"," |  \n"," |  ----------------------------------------------------------------------\n"," |  Methods inherited from sklearn.base.ClassifierMixin:\n"," |  \n"," |  score(self, X, y, sample_weight=None)\n"," |      Return the mean accuracy on the given test data and labels.\n"," |      \n"," |      In multi-label classification, this is the subset accuracy\n"," |      which is a harsh metric since you require for each sample that\n"," |      each label set be correctly predicted.\n"," |      \n"," |      Parameters\n"," |      ----------\n"," |      X : array-like of shape (n_samples, n_features)\n"," |          Test samples.\n"," |      \n"," |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n"," |          True labels for X.\n"," |      \n"," |      sample_weight : array-like of shape (n_samples,), default=None\n"," |          Sample weights.\n"," |      \n"," |      Returns\n"," |      -------\n"," |      score : float\n"," |          Mean accuracy of self.predict(X) wrt. y.\n"," |  \n"," |  ----------------------------------------------------------------------\n"," |  Data descriptors inherited from sklearn.base.ClassifierMixin:\n"," |  \n"," |  __dict__\n"," |      dictionary for instance variables (if defined)\n"," |  \n"," |  __weakref__\n"," |      list of weak references to the object (if defined)\n"," |  \n"," |  ----------------------------------------------------------------------\n"," |  Methods inherited from sklearn.svm._base.BaseLibSVM:\n"," |  \n"," |  fit(self, X, y, sample_weight=None)\n"," |      Fit the SVM model according to the given training data.\n"," |      \n"," |      Parameters\n"," |      ----------\n"," |      X : {array-like, sparse matrix}, shape (n_samples, n_features)\n"," |          Training vectors, where n_samples is the number of samples\n"," |          and n_features is the number of features.\n"," |          For kernel=\"precomputed\", the expected shape of X is\n"," |          (n_samples, n_samples).\n"," |      \n"," |      y : array-like, shape (n_samples,)\n"," |          Target values (class labels in classification, real numbers in\n"," |          regression)\n"," |      \n"," |      sample_weight : array-like, shape (n_samples,)\n"," |          Per-sample weights. Rescale C per sample. Higher weights\n"," |          force the classifier to put more emphasis on these points.\n"," |      \n"," |      Returns\n"," |      -------\n"," |      self : object\n"," |      \n"," |      Notes\n"," |      -----\n"," |      If X and y are not C-ordered and contiguous arrays of np.float64 and\n"," |      X is not a scipy.sparse.csr_matrix, X and/or y may be copied.\n"," |      \n"," |      If X is a dense array, then the other methods will not support sparse\n"," |      matrices as input.\n"," |  \n"," |  ----------------------------------------------------------------------\n"," |  Data descriptors inherited from sklearn.svm._base.BaseLibSVM:\n"," |  \n"," |  coef_\n"," |  \n"," |  n_support_\n"," |  \n"," |  ----------------------------------------------------------------------\n"," |  Methods inherited from sklearn.base.BaseEstimator:\n"," |  \n"," |  __getstate__(self)\n"," |  \n"," |  __repr__(self, N_CHAR_MAX=700)\n"," |      Return repr(self).\n"," |  \n"," |  __setstate__(self, state)\n"," |  \n"," |  get_params(self, deep=True)\n"," |      Get parameters for this estimator.\n"," |      \n"," |      Parameters\n"," |      ----------\n"," |      deep : bool, default=True\n"," |          If True, will return the parameters for this estimator and\n"," |          contained subobjects that are estimators.\n"," |      \n"," |      Returns\n"," |      -------\n"," |      params : mapping of string to any\n"," |          Parameter names mapped to their values.\n"," |  \n"," |  set_params(self, **params)\n"," |      Set the parameters of this estimator.\n"," |      \n"," |      The method works on simple estimators as well as on nested objects\n"," |      (such as pipelines). The latter have parameters of the form\n"," |      ``<component>__<parameter>`` so that it's possible to update each\n"," |      component of a nested object.\n"," |      \n"," |      Parameters\n"," |      ----------\n"," |      **params : dict\n"," |          Estimator parameters.\n"," |      \n"," |      Returns\n"," |      -------\n"," |      self : object\n"," |          Estimator instance.\n","\n"],"name":"stdout"}]}]}